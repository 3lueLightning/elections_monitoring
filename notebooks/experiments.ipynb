{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel, Field, field_validator, ValidationInfo\n",
    "import pandas as pd\n",
    "\n",
    "Probability = Annotated[float, Field(strict=True, ge=0, le=1)]\n",
    "\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    quote: str = Field(..., min_length=3)\n",
    "    score: Probability\n",
    "    author: str = Field(None, min_length=3, max_length=255)\n",
    "    \n",
    "    @field_validator('quote')\n",
    "    @classmethod\n",
    "    def citation_exists(cls, v: str, info: ValidationInfo):  \n",
    "        context = info.context\n",
    "        if context:\n",
    "            context = context.get('article_n_meta')\n",
    "            quote_in_article = any({v in elem for elem in context})\n",
    "            if not quote_in_article:\n",
    "                raise ValueError(f\"Citation `{v}` not found in article_n_meta\")\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(BaseModel):\n",
    "    name: str\n",
    "    score: float | None\n",
    "    citations: list[Citation]\n",
    "\n",
    "    @field_validator(\"citations\")\n",
    "    @classmethod\n",
    "    def check_score_iff_citations(cls, citations, values):\n",
    "        score = values.data[\"score\"]\n",
    "        no_score_no_citations = score is None and not citations\n",
    "        score_and_citations = score is not None and citations\n",
    "        \n",
    "        if no_score_no_citations or score_and_citations:\n",
    "            return citations\n",
    "        \n",
    "        raise ValueError(\"Either both a score and citations are present\\\n",
    "            or neither are.\")\n",
    "    \n",
    "    @field_validator(\"name\")\n",
    "    @classmethod\n",
    "    def validate_politicians(cls, name: str, info: ValidationInfo):\n",
    "        context = info.context\n",
    "        if context:\n",
    "            context = context.get('article_n_meta')\n",
    "            politican_in_article = any({name in elem for elem in context})\n",
    "            if not politican_in_article:\n",
    "                raise ValueError(f\"Citation `{name}` not found in article_n_meta\")\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(name='Pedro Nuno Santos', score=0.5, citations=[Citation(quote='the quick brown fox jumps over the lazy dog', score=0.5, author='John Doe')])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentiment.model_validate(\n",
    "    {\"name\": \"Pedro Nuno Santos\", \"score\": .5, \"citations\": [cite]},\n",
    "    context={\"article_n_meta\": [\"Pedro Nuno Santos\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pedro Nuno Santos, Mariana Mortágua, Rui Tavares'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elections import constants\n",
    "\n",
    "article = \"Mariana Mortágua falou com Vasco da gama sobre a inflação. \\\n",
    "    Enquanto Rui Tavares explicava o sentido da vida a Pedro Nuno Santos\"\n",
    "\n",
    "\", \".join([politician for politician in constants.POLITICIANS if politician in article])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue with loggin in VScode: solve by applying \n",
    "https://stackoverflow.com/questions/63872967/duplicate-log-lines-in-vscode-when-debugging-asp-net-core-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is an warning iubtyiugvyt\n",
      "This is an warning iubtyiugvyt\n",
      "This is an warning iubtyiugvyt\n",
      "This is an warning iubtyiugvyt\n",
      "This is an warning iubtyiugvyt\n",
      "This is an warning iubtyiugvyt\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "name = \"uibuybyu\"\n",
    "logger = logging.getLogger(name)\n",
    "ch: logging.Handler = logging.StreamHandler()\n",
    "logger.addHandler(ch)\n",
    "\n",
    "    \n",
    "logger.info(\"This is a test inuygyubuyvtyhytv\")\n",
    "logger.warning(\"This is an warning iubtyiugvyt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elections",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
