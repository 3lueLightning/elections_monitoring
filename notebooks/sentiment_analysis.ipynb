{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import sqlite3\n",
    "import instructor\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from pydantic import ValidationError\n",
    "\n",
    "from elections import constants\n",
    "from elections.utils import full_logger\n",
    "from elections.data_schemas import ArticleSentiment\n",
    "from elections.scrapers.news_scraper import NewsScraper\n",
    "from elections.prompts.templates import sentiment_template\n",
    "\n",
    "\n",
    "#logger = full_logger(constants.LOG_LVL, constants.SENTIMENT_LOG_FN, to_console=False)\n",
    "\n",
    "\n",
    "class SentimentAnalysis:\n",
    "    def __init__(self):\n",
    "        self.client = instructor.patch(OpenAI())\n",
    "        self.articles_df = pd.DataFrame()\n",
    "        self.sentiments = []\n",
    "        self.articles_counter = 0\n",
    "        \n",
    "    def load_articles(self, n_articles=None, refresh=False, query=None) -> None:\n",
    "        if query is not None:\n",
    "            self.articles_df = NewsScraper.load_articles(query)\n",
    "            return\n",
    "        if refresh:\n",
    "            query = \"SELECT article_id, title, description, text FROM articles\"\n",
    "        else:\n",
    "            query = \"\"\"\n",
    "                SELECT \n",
    "                    atc.article_id, title, description, text\n",
    "                FROM articles atc\n",
    "                LEFT JOIN article_sentiments atc_s\n",
    "                ON atc.article_id = atc_s.article_id\n",
    "                WHERE atc_s.analysis IS NULL\n",
    "            \"\"\"\n",
    "        if n_articles is not None:\n",
    "            query = f\"{query} LIMIT {n_articles}\"\n",
    "        self.articles_df = NewsScraper.load_articles(query)\n",
    "    \n",
    "    def get_article_sentiment(self, title, description, text) -> pd.DataFrame:\n",
    "        system_prompt = sentiment_template.SYSTEM_PROMPT\n",
    "        user_prompt = sentiment_template.USER_PROMPT.format(title=title, description=description, text=text)\n",
    "        \n",
    "        try:\n",
    "            # to see the raw response: resp._raw_response.model_dump_json(indent=2)\n",
    "            resp = self.client.chat.completions.create(\n",
    "                model=constants.OPENAI_GPT_MODEL,\n",
    "                response_model=ArticleSentiment,\n",
    "                max_retries=constants.MAX_RETRIES,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "            )\n",
    "        except ValidationError:\n",
    "            resp = None\n",
    "        \n",
    "        return pd.DataFrame({\"analysis\": [resp], \"system_prompt\": [system_prompt], \"user_prompt\": [user_prompt]})\n",
    "        \n",
    "    \n",
    "    def get_sentiments(self, freq=5, save=True) -> Optional[pd.DataFrame]:\n",
    "        assert not self.articles_df.empty, \"No articles loaded\"\n",
    "        N = len(self.articles_df)\n",
    "        \n",
    "        if save:\n",
    "            engine = sqlite3.connect(constants.NEWS_DB)\n",
    "        \n",
    "        self.sentiments = []\n",
    "        for i, row in tqdm(self.articles_df.reset_index().iterrows(), total=N):\n",
    "            #if i % freq == 0:\n",
    "                #logger.info(f\"Processing article {i + 1} of {N}\")\n",
    "                #print(f\"Processing article {i + 1} of {N}\")\n",
    "            sentiment = self.get_article_sentiment(row[\"title\"], row[\"description\"], row[\"text\"])\n",
    "            sentiment.insert(loc=0, column=\"article_id\", value=row[\"article_id\"])\n",
    "            if not sentiment.empty:\n",
    "                self.sentiments.append(sentiment)\n",
    "                self.articles_counter += 1\n",
    "                if self.articles_counter % freq == 0 or i == N - 1:\n",
    "                    if save:\n",
    "                        self._save_sentiments(engine)\n",
    "                    else:\n",
    "                        #logger.info(f\"Extracted {self.articles_counter} of {N}\")\n",
    "                        print(f\"Extracted {self.articles_counter} of {N}\")\n",
    "        if save:\n",
    "            engine.close()\n",
    "            return None\n",
    "        \n",
    "        return self.sentiments\n",
    "    \n",
    "    def _save_sentiments(self, engine) -> None:\n",
    "        sentiments_df = pd.concat(self.sentiments)\n",
    "        sentiments_df[\"analysis\"] = sentiments_df[\"analysis\"].apply(lambda x: x.model_dump_json())\n",
    "        sentiments_df.to_sql(\"article_sentiments\", con=engine, if_exists=\"append\", index=False)\n",
    "        self.sentiments = []\n",
    "        #logger.info(f\"Saved in DB {self.articles_counter} of {N}\")\n",
    "        print(f\"Saved in DB {self.articles_counter} of {len(self.articles_df)}\")\n",
    "    \n",
    "    def load_article_sentiments(query) -> pd.DataFrame:\n",
    "        with sqlite3.connect(constants.NEWS_DB) as engine:\n",
    "            df = pd.read_sql(\"SELECT * FROM article_sentiments\", con=engine)\n",
    "        if \"analysis\" in df.columns:\n",
    "            df[\"analysis\"] = df[\"analysis\"].apply(lambda x: ArticleSentiment.model_validate_json(x))\n",
    "        return df\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Pedro Nuno Santos vs André Ventura: oiça aqui ...</td>\n",
       "      <td>Pedro Nuno Santos vs André Ventura: oiça aqui ...</td>\n",
       "      <td>Ouça o frente a frente entre o secretário-gera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Podcast. Afinal, Pedro Nuno Santos não está de...</td>\n",
       "      <td>Podcast. Afinal, Pedro Nuno Santos não está de...</td>\n",
       "      <td>A maior trapalhada do líder do PS deu espaço a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0           3  Pedro Nuno Santos vs André Ventura: oiça aqui ...   \n",
       "1           4  Podcast. Afinal, Pedro Nuno Santos não está de...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Pedro Nuno Santos vs André Ventura: oiça aqui ...   \n",
       "1  Podcast. Afinal, Pedro Nuno Santos não está de...   \n",
       "\n",
       "                                                text  \n",
       "0  Ouça o frente a frente entre o secretário-gera...  \n",
       "1  A maior trapalhada do líder do PS deu espaço a...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis = SentimentAnalysis()\n",
    "sentiment_analysis.load_articles() #n_articles=2)#, refresh=True)\n",
    "sentiment_analysis.articles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/04/2024 04:21:29 PM - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/q3/m5wwnysd3kx0n1_6yvsrqghh0000gn/T/ipykernel_37555/390412390.py\u001b[0m(68)\u001b[0;36mget_article_sentiment\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     66 \u001b[0;31m            \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 68 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"analysis\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"system_prompt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"user_prompt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     69 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ArticleSentiment(sentiments=[Sentiment(name='Pedro Nuno Santos', score=None, citations=[]), Sentiment(name='André Ventura', score=None, citations=[])])\n",
      "'{\\n  \"id\": \"chatcmpl-8z5M7uItpaA1gnYbhZsTHT7WGlWU0\",\\n  \"choices\": [\\n    {\\n      \"finish_reason\": \"stop\",\\n      \"index\": 0,\\n      \"logprobs\": null,\\n      \"message\": {\\n        \"content\": null,\\n        \"role\": \"assistant\",\\n        \"function_call\": null,\\n        \"tool_calls\": [\\n          {\\n            \"id\": \"call_t1biobcJhffHcw2fo5IIY6a2\",\\n            \"function\": {\\n              \"arguments\": \"{\\\\\"sentiments\\\\\":[{\\\\\"name\\\\\":\\\\\"Pedro Nuno Santos\\\\\",\\\\\"score\\\\\":null,\\\\\"citations\\\\\":[]},{\\\\\"name\\\\\":\\\\\"André Ventura\\\\\",\\\\\"score\\\\\":null,\\\\\"citations\\\\\":[]}]}\",\\n              \"name\": \"ArticleSentiment\"\\n            },\\n            \"type\": \"function\"\\n          }\\n        ]\\n      }\\n    }\\n  ],\\n  \"created\": 1709569287,\\n  \"model\": \"gpt-4-0125-preview\",\\n  \"object\": \"chat.completion\",\\n  \"system_fingerprint\": \"fp_00ceb2df5b\",\\n  \"usage\": {\\n    \"completion_tokens\": 36,\\n    \"prompt_tokens\": 1447,\\n    \"total_tokens\": 1483\\n  }\\n}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [01:26<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis.get_sentiments(freq=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elections",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
